#CIFAR-10 Image Classification using Transfer Learning

Comparative analysis of VGG16, ResNet50, and MobileNetV2 architectures for CIFAR-10 image classification using transfer learning with pre-trained ImageNet weights.

## ğŸ“‹ Overview

This project implements and compares three state-of-the-art CNN architectures (VGG16, ResNet50, MobileNetV2) for image classification on the CIFAR-10 dataset. The models utilize transfer learning by freezing pre-trained ImageNet weights and training custom classifier heads.

**Key Results:**
- VGG16: **60.74%** test accuracy (best performer)
- ResNet50: 50.55% test accuracy
- MobileNetV2: 34.17% test accuracy (fastest training)

## ğŸ¯ Features

- Transfer learning with frozen pre-trained weights
- Custom classifier head architecture
- Data augmentation (rotation, shifts, flips, zoom)
- Comprehensive evaluation metrics (accuracy, precision, recall, F1-score)
- Training visualization (accuracy/loss curves)
- Per-class performance analysis
- Confusion matrix generation
- Model checkpointing and early stopping

## ğŸ› ï¸ Requirements
See [requirements.txt](requirements.txt) for dependencies.

```
tensorflow>=2.19.0
numpy>=2.0.2
matplotlib>=3.10.0
seaborn>=0.13.2
pandas>=2.2.2
scikit-learn>=1.6.1
```

## ğŸ“¦ Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/cifar10-transfer-learning.git
cd cifar10-transfer-learning

# Install dependencies
pip install -r requirements.txt
```

## ğŸš€ Usage

### Quick Start

Run the complete pipeline in Google Colab or Jupyter Notebook:

```python
# The notebook will automatically:
# 1. Load and preprocess CIFAR-10 dataset
# 2. Train all three models
# 3. Generate visualizations
# 4. Save results and trained models
```

### Training Individual Models

```python
# Train VGG16
model = build_transfer_model('VGG16', input_shape=(32, 32, 3), num_classes=10)
history = model.fit(train_data, validation_data=val_data, epochs=30)

# Train ResNet50
model = build_transfer_model('ResNet50', input_shape=(32, 32, 3), num_classes=10)

# Train MobileNetV2
model = build_transfer_model('MobileNetV2', input_shape=(32, 32, 3), num_classes=10)
```

## ğŸ“Š Dataset

**CIFAR-10** consists of 60,000 32Ã—32 color images in 10 classes:
- Training: 50,000 images (split to 40,000 train / 10,000 validation)
- Test: 10,000 images
- Classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck

## ğŸ—ï¸ Model Architecture

Each model follows the same structure:

```
Input (32Ã—32Ã—3)
    â†“
Pre-trained Base (frozen)
    â†“
Global Average Pooling
    â†“
Batch Normalization
    â†“
Dense(256, ReLU) + Dropout(0.5)
    â†“
Batch Normalization
    â†“
Dense(128, ReLU) + Dropout(0.3)
    â†“
Dense(10, Softmax)
```

**Base Models:**
- **VGG16**: 14.9M total params, 167K trainable
- **ResNet50**: 24.2M total params, 563K trainable
- **MobileNetV2**: 2.6M total params, 365K trainable

## ğŸ“ˆ Results

### Overall Performance

| Model | Accuracy | Precision | Recall | F1-Score | Training Time |
|-------|----------|-----------|--------|----------|---------------|
| VGG16 | **60.74%** | 0.606 | 0.607 | 0.602 | 15.4 min |
| ResNet50 | 50.55% | 0.503 | 0.506 | 0.492 | 16.0 min |
| MobileNetV2 | 34.17% | 0.351 | 0.342 | 0.338 | 11.4 min |

### Per-Class Accuracy (VGG16)

| Class | Accuracy |
|-------|----------|
| Ship | 72.1% |
| Automobile | 71.2% |
| Airplane | 69.1% |
| Frog | 68.3% |
| Truck | 67.2% |
| Horse | 66.1% |
| Deer | 54.4% |
| Dog | 52.1% |
| Bird | 47.8% |
| Cat | 44.1% |

## ğŸ“ Project Structure

```
â”œâ”€â”€ CV_DL_ASSGN4.ipynb          # Main notebook with all experiments
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ model_comparison.csv    # Numerical results
â”‚   â”œâ”€â”€ detailed_results.json   # Complete metrics
â”‚   â”œâ”€â”€ training_curves.png     # Training/validation curves
â”‚   â”œâ”€â”€ confusion_matrices.png  # Confusion matrices
â”‚   â”œâ”€â”€ metrics_comparison.png  # Bar chart comparisons
â”‚   â””â”€â”€ per_class_accuracy.png  # Per-class performance
â””â”€â”€ models/
    â”œâ”€â”€ VGG16_best_model.h5
    â”œâ”€â”€ ResNet50_best_model.h5
    â””â”€â”€ MobileNetV2_best_model.h5
```

## ğŸ”§ Training Configuration

**Hyperparameters:**
- Optimizer: Adam (lr=0.001, Î²â‚=0.9, Î²â‚‚=0.98)
- Batch size: 64
- Epochs: 30 (with early stopping)
- Loss: Sparse categorical cross-entropy
- Callbacks: EarlyStopping (patience=5), ModelCheckpoint, ReduceLROnPlateau

**Data Augmentation:**
- Rotation: Â±15Â°
- Width/height shift: 10%
- Horizontal flip: 50% probability
- Zoom: 10%

## ğŸ’¡ Key Findings

1. **VGG16 outperforms complex architectures** - Simple uniform architecture works best for low-resolution images
2. **Transfer learning limitations** - Frozen pre-trained features struggle with 32Ã—32 resolution (designed for 224Ã—224)
3. **Vehicle classes easiest** - All models perform best on ship, automobile, truck
4. **Animal classes challenging** - Cat, dog, bird show lowest accuracy across all models
5. **Efficiency trade-off** - MobileNetV2 fastest but sacrifices 26% accuracy compared to VGG16

## ğŸ”¬ Future Work

- [ ] Fine-tune top layers instead of freezing all weights
- [ ] Upsample CIFAR-10 images to 224Ã—224 for better transfer learning
- [ ] Implement ensemble methods combining multiple models
- [ ] Test advanced augmentation (MixUp, CutMix, AutoAugment)
- [ ] Compare with training from scratch
- [ ] Add attention mechanisms

## ğŸ“ Citation

If you use this code for your research, please cite:

```bibtex
@misc{samantaray2025cifar10transfer,
  author = {Samantaray, Prabhupada},
  title = {Comparative Analysis of Pre-trained CNN Architectures for CIFAR-10},
  year = {2025},
  institution = {KIIT University},
  howpublished = {\url{https://github.com/prabhu-313/cifar10-transfer-learning}}
}
```

## ğŸ“„ License

This project is licensed under the [MIT License](LICENSE).

## ğŸ‘¤ Author

**Prabhupada Samantaray**
- Institution: KIIT University, Bhubaneswar, Odisha, India
- Email: 22052483@kiit.ac.in

## ğŸ™ Acknowledgments

- KIIT University for computational resources
- TensorFlow/Keras team for excellent framework
- CIFAR-10 dataset creators

## ğŸ“š References

1. Simonyan & Zisserman, "Very Deep Convolutional Networks" (VGG16)
2. He et al., "Deep Residual Learning for Image Recognition" (ResNet)
3. Sandler et al., "MobileNetV2: Inverted Residuals and Linear Bottlenecks"
4. Krizhevsky & Hinton, "Learning Multiple Layers of Features from Tiny Images" (CIFAR-10)

---

â­ If you find this project helpful, please consider giving it a star!

